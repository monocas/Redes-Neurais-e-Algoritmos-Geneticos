# Experimentos de redes neurais artificiais  üß† üíª üß¨

<p align="justify"> Ol√° computeiros! Vamos iniciar a nossa jornada para aprender mais sobre algoritmos gen√©ticos? :ok_woman: </p>

<p align="justify"> Caso voc√™ tenha perdido a nossa introdu√ß√£o b√°sica de redes neurais no README.md geral, sem problemas, vamos retornar a discuss√£o por agora! :ok_woman: </p>

<h3 align="justify">  O QUE S√ÉO REDES NEURAIS? </h3>

<p align="justify">  Redes neurais s√£o algoritmos que se baseiam em um processamento de dados similar ao processamento de informa√ß√µes de um c√©rebro humano que ocorrem por meio de um conjunto extremamente complexo de c√©lulas, os neur√¥nios, respons√°veis pela tomada de decis√£o do racioc√≠nio e corpo humanos. Os neur√¥nios s√£o formados por dendritos ‚Äì conjuntos de terminais de entrada, pelo corpo central, e pelos ax√¥nios ‚Äì terminais de sa√≠das. </p>
<p align="justify">  A comunica√ß√£o dos neur√¥nios ocorrem por meia da sinapse ‚Äì regi√£o onde dois neur√¥nios entram em contato e transmitem impulsos nervosos. Estabelecido o funcionamento biol√≥gico, observa-se que o comportamento das redes neurais √© similar ao de um neur√¥nio visto que a estrutura computacional √© baseada em um sistema tr√™s camadas, sendo um de input - valor de entrada; a camada escondida - neur√¥nio soma os valores de entrada recebidos e incrementa um vi√©s; e por fim, o output - valor de sa√≠da das opera√ß√µes. Na Figura 1, h√° a exemplifica√ß√£o estrutural de uma rede neural. </p>
 
<p align="justify"><img src="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/assets/106678040/4bfe07bf-4ac7-4d40-9bee-f07274d90472" width="500" height="300" > </p>
Figura 1. Estrutura de camadas das Redes Neurais.
<br> </br>

<p align="justify"> E o porque as redes neurais s√£o t√£o admiradas e utilizas? Esse processamento de dados similar ao processamento de informa√ß√µes de um c√©rebro humano nos permitem realizar projetos de previs√£o e an√°lise de dados seja predizendo seres temporais como as a√ß√µes do mercado financeiro como tamb√©m predizendo dados de sa√∫de p√∫blica, ademais, as redes neurais tamb√©m podem ter aplica√ß√µes em sistemas de recomenda√ß√£o e tamb√©m no desenvolvimento de IA's, quem n√£o conhece o famoso Chat GPT? </p>

<p align="justify">  Existem in√∫meros modos de categoriza√ß√£o de redes conforme os dados fluem dos "n√≥s" de entrada para os "n√≥s de sa√≠da". Abordamos, neste reposit√≥rio, os algoritmos de backpropagation.  </p>

<h4 align="justify"> BACKPROPAGATION </h4>

<p align="justify">  Este algoritmo √© muito utilizado em redes neurais devido o ajuste do peso das conex√µes entre os neur√¥nios com o objetivo de minimizar o erro entre as sa√≠das da rede e os valores desejados. O processo em duas etapas: propaga√ß√£o para frente (forward propagation) e retropropaga√ß√£o do erro (backward propagation). </p>
  
<p align="justify">  O primeiro processo considerada os dados de entrada alimentados na rede e os valores de sa√≠da c√°lculados a partir da ativa√ß√£o dos neurNa etapa de propaga√ß√£o para frente, os dados de entrada s√£o alimentados na rede, e as sa√≠das s√£o calculadas atrav√©s das ativa√ß√µes dos neur√¥nios, por sua vez, o segundo processo, determina que o erro entre as sa√≠das da rede e os valores desejados √© propagado de volta para a rede, ademais, os pesos das conex√µes s√£o atualizados de forma a se obter um erro m√≠nimo, utilizando o gradiente que √© calculado atrav√©s da derivada parcial do erro em rela√ß√µes aos pesos - al√¥ Regra da Cadeia; e s√£o repetidos at√© que a rede forne√ßa uma sa√≠da com um erro aceit√°vel.  </p>

<hr>

<h3 align="justify"> O QUE FAZEMOS NESTA SE√á√ÉO? </h3>

<p align="justify">  Nesta se√ß√£o, iremos discorrer a respeito das atividades desenvolvidas e fun√ß√µes necess√°rias para os c√≥digos, no total ser√£o desenvolvidos sete experimentos que visam introduzir conceitos de gen√©tica em computa√ß√£o de modo a se utilizar das redes neurais. Todas as atividades foram desenvolvidas pelo Professor Daniel Cassar, docente da Ilum - School of Science. </p>

<p align="justify"> Existem dois tipos de arquivos nesta se√ß√£o, os arquivos .ipynb definem os experimentos desenvolvidos, enquanto os do tipo .py se tratam de ferramentas auxiliadoras de c√≥digo afim de otimiza-lo.</p>

<p align="justify"> Ok! Dada a introduzida b√°sica, bora programar?</p>

<p align="justify"><img src="https://user-images.githubusercontent.com/106678040/225717363-f85c2c46-c3c2-4193-8d80-bdf15d48d438.gif" width="300" height="300" > </p>

## Arquivos .ipynb
<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/experimento%20R.01%20-%20derivadas.ipynb"> Experimento R.01 </a> - derivadas.ipynb - Neste arquivo, abordamos o problema do calculo da derivada de uma fun√ß√£o qualquer de forma num√©rica usando a defini√ß√£o. </p>

<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/experimento%20R.02%20-%20classes.ipynb"> Experimento R.02 </a> - classes.ipynb - Nesta arquivo, aborda-se uma introdu√ß√£o a respeito de opera√ß√µes com classes. </p>
</p>

<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/experimento%20R.03%20-%20construindo%20um%20grafo%20automaticamente.ipynb"> Experimento R.03 </a> - construindo um grafo automaticamente.ipynb - Neste arquivo, abordamos a constru√ß√£o de grafos por meio de classes que geram automaticamente o grafo computacional. </p>

<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/experimento%20R.04%20-%20computando%20gradientes%20locais.ipynb"> Experimento R.04 </a> - construindo um grafo automaticamente.ipynb -  Neste notebook n√≥s vamos atualizar a classe `Valor` para que ela seja capaz de computar o gradiente local de cada v√©rtice num√©rico do grafo computacional. Esse c√°lculo ser√° feito &ldquo;de tr√°s para frente&rdquo;, iniciando pelo v√©rtice folha e retornando at√© os v√©rtices raiz. O nome desse processo √© `backpropagation` e √© o cora√ß√£o do processo de treinar uma rede neural artificial.
</p>

<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/experimento%20R.03%20-%20construindo%20um%20grafo%20automaticamente.ipynb"> Experimento R.05 </a> - construindo um grafo automaticamente.ipynb -  Neste arquivo, o objetivo √© fazer com que a classe `Valor` seja capaz de realizar algumas opera√ß√µes necess√°rias para que seja usada na nossa rede neural artificial.
</p>

<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/experimento%20R.03%20-%20construindo%20um%20grafo%20automaticamente.ipynb"> Experimento R.06 </a> - redes neurais artificais.ipynb - Neste arquivo, iremos abordar a constru√ß√£o de uma rede neural por partes, primeiramente criando um neur√¥nio artificial, depois uma camada de neur√¥nios e, por fim, uma rede neural multicamadas.
. </p>

<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/experimento%20R.03%20-%20construindo%20um%20grafo%20automaticamente.ipynb"> Experimento R.07 </a> - treinando uma rede neural.ipynb - Neste arquivo, estamos no gran finale de redes neurais em que finalmente treinamos a nossa rede neural artificial tipo Multilayer Perceptron usando Python. </p>

<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/experimento%20R.03%20-%20construindo%20um%20grafo%20automaticamente.ipynb"> Experimento R.08 </a> - Treinando uma rede neural usando pytorch.ipynb - Neste arquivo, temos um spin off  do nosso gran finale sobre redes neurais, isto √©, aprendemos a treinar uma rede neural artificial tipo Multilayer Perceptron usando `pytorch`.</p>


## Arquivos .py
<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/constantes.py">  constantes.py </a> - Neste arquivo est√£o alocadas todas as constantes utilizadas nos c√≥digos fonte para a resolu√ß√£o dos exerc√≠cios. √â um ambiente destinado para guardar e armazenar as constantes de modo a otimizar o c√≥digo. </p>

<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/classes.py">  classes.py </a> - Neste arquivo est√£o alocados todas as classes criadas com o objetivo de auxiliar na otimiza√ß√£o do c√≥digo. </p>

<p align="justify">
:white_check_mark: <a href="https://github.com/monocas/Redes-Neurais-e-Algoritmos-Geneticos/blob/main/RedesNeurais/funcoes.py"> funcoes.py </a> - Neste arquivo est√£o alocadas todas as fun√ß√µes desenvolvidas e utilizadas nos c√≥digos fonte para a resolu√ß√£o dos exerc√≠cios. √â um ambiente destinado para as fun√ß√µes e suas implementa√ß√µes. </p>


